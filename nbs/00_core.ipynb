{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Decision Tree to Compress an Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_images/bw_5.png\" width=\"19%\" /> <img src=\"output_images/bw_8.png\" width=\"19%\" /> <img src=\"output_images/bw_14.png\" width=\"19%\" /> <img src=\"output_images/bw_30.png\" width=\"19%\" />\n",
    "\n",
    "<img src=\"output_images/hsv_30.png\" width=\"19%\" /> <img src=\"output_images/hsv_14.png\" width=\"19%\" /> <img src=\"output_images/hsv_8.png\" width=\"19%\" /> <img src=\"output_images/hsv_5.png\" width=\"19%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_gifs/animated_bw.gif\" width=\"30%\" /> <img src=\"output_gifs/animated_rgb.gif\" width=\"30%\" /> <img src=\"output_gifs/animated_hsv.gif\" width=\"30%\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# todo:\n",
    "# skip_showdoc: true\n",
    "# skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from joblib import Memory, dump, load\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageSequence\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the final gif\n",
    "left_pad = 80\n",
    "upper_pad = 40\n",
    "lower_pad = 100\n",
    "\n",
    "model_results = {}\n",
    "color_models = [\"bw\", \"rgb\", \"hsv\"]\n",
    "\n",
    "font = ImageFont.truetype(\"../font/Roboto-Regular.ttf\", 250)\n",
    "font_small = ImageFont.truetype(\"../font/Roboto-Regular.ttf\", 100)\n",
    "\n",
    "memory = Memory(\"cache_directory\", verbose=0)\n",
    "max_depths = range(1, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(data, color_model):\n",
    "    \"\"\"\n",
    "    Process an image and create a coordinate array and a representation of the image.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): The input image data.\n",
    "    color_model (str): The color model of the image. Can be 'bw', 'rgb', or 'hsv'.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The coordinate array for the image.\n",
    "    numpy.ndarray: The representation of the image.\n",
    "    \"\"\"\n",
    "    if color_model not in [\"bw\", \"rgb\", \"hsv\"]:\n",
    "        raise ValueError(\"color_model must be 'bw', 'rgb', or 'hsv'\")\n",
    "    if color_model == \"bw\":\n",
    "        # Convert the image to grayscale\n",
    "        data_bw = cv2.cvtColor(data, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Get the dimensions of the image\n",
    "        rows_bw, cols_bw = data_bw.shape\n",
    "\n",
    "        # Create a coordinate array for the image\n",
    "        X = np.array([(row, col) for row in range(rows_bw) for col in range(cols_bw)])\n",
    "\n",
    "        # Reshape the data array into a column vector\n",
    "        y = data_bw.reshape(-1, 1)\n",
    "    elif color_model == \"hsv\":\n",
    "        # Convert the image to HSV\n",
    "        data_hsv = cv2.cvtColor(data, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        # Get the dimensions of the image\n",
    "        rows_hsv, cols_hsv, bands_hsv = data_hsv.shape\n",
    "\n",
    "        # Create a coordinate array for the image\n",
    "        X = np.array([(row, col) for row in range(rows_hsv) for col in range(cols_hsv)])\n",
    "\n",
    "        # Extract hue, saturation, and value\n",
    "        hue, sat, val = cv2.split(data_hsv)\n",
    "        hue = hue / 179.0 * np.pi * 2.0  # Convert hue to radians\n",
    "\n",
    "        # Create two-dimensional representation of hue and saturation\n",
    "        hue_x = np.cos(hue).reshape(-1, 1)\n",
    "        hue_y = np.sin(hue).reshape(-1, 1)\n",
    "        sat = sat.reshape(-1, 1)\n",
    "        val = val.reshape(-1, 1)\n",
    "\n",
    "        # Stack hue_x, hue_y, sat, and val to create y_hsv\n",
    "        y = np.hstack((hue_x, hue_y, sat, val))\n",
    "    elif color_model == \"rgb\":\n",
    "        # Create coordinate arrays using mgrid\n",
    "        row_coords, col_coords, band_coords = np.mgrid[\n",
    "            : data.shape[0], : data.shape[1], : data.shape[2]\n",
    "        ]\n",
    "\n",
    "        # Reshape the coordinate arrays into a single array\n",
    "        X = np.column_stack(\n",
    "            (row_coords.ravel(), col_coords.ravel(), band_coords.ravel())\n",
    "        )\n",
    "\n",
    "        # Reshape the data array into a column vector\n",
    "        y = data.reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def create_regressor_and_image(X, y, data, max_depth, color_model):\n",
    "    \"\"\"\n",
    "    Create a Decision Tree Regressor, fit it to the data, make predictions, and convert the predictions to an image.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): The input features for the regressor.\n",
    "    y (numpy.ndarray): The target output for the regressor.\n",
    "    data (numpy.ndarray): The original image data used to reshape the predicted array.\n",
    "    max_depth (int): The maximum depth of the tree.\n",
    "    color_model (str): The color model of the image. Can be 'bw', 'rgb', or 'hsv'.\n",
    "\n",
    "    Returns:\n",
    "    DecisionTreeRegressor: The fitted regressor.\n",
    "    PIL.Image.Image: The image created from the predictions.\n",
    "    \"\"\"\n",
    "    # Check that the color model is one of the expected values\n",
    "    if color_model not in [\"bw\", \"rgb\", \"hsv\"]:\n",
    "        raise ValueError(\"color_model must be 'bw', 'rgb', or 'hsv'\")\n",
    "\n",
    "    # Create the regressor\n",
    "    regressor = DecisionTreeRegressor(max_depth=max_depth)\n",
    "\n",
    "    # Fit the regressor to the data\n",
    "    regressor.fit(X, y)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = regressor.predict(X)\n",
    "\n",
    "    if color_model == \"bw\":\n",
    "        # Reshape the predictions to the original image shape\n",
    "        y_pred_reshaped = y_pred.reshape(data.shape[0], data.shape[1])\n",
    "\n",
    "        # Stack the reshaped predictions to create a 3-channel image\n",
    "        y_pred = np.stack((y_pred_reshaped,) * 3, axis=-1)\n",
    "\n",
    "    elif color_model == \"hsv\":\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "\n",
    "        # Convert the predictions to HSV format\n",
    "        y_pred_hue = (\n",
    "            np.arctan2(y_pred[:, 1], y_pred[:, 0]) % (2 * np.pi) / (2 * np.pi) * 179.0\n",
    "        ).astype(np.uint8)  # Convert hue to degrees\n",
    "        y_pred_sat = y_pred[:, 2].astype(np.uint8)\n",
    "        y_pred_val = y_pred[:, 3].astype(np.uint8)\n",
    "        y_pred = cv2.merge((y_pred_hue, y_pred_sat, y_pred_val))\n",
    "\n",
    "        # Convert to RGB format\n",
    "        y_pred = cv2.cvtColor(y_pred, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    # Reshape the predictions to the original image shape and convert to an image\n",
    "    image = Image.fromarray(y_pred.reshape(data.shape).astype(np.uint8))\n",
    "\n",
    "    return regressor, image\n",
    "\n",
    "\n",
    "def convert_to_bw_image(data):\n",
    "    \"\"\"\n",
    "    Convert an image to black and white.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): The input image data.\n",
    "\n",
    "    Returns:\n",
    "    PIL.Image.Image: The black and white image.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale\n",
    "    data_bw = cv2.cvtColor(data, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Convert the grayscale array to an image\n",
    "    bw_image = Image.fromarray(data_bw.astype(np.uint8))\n",
    "\n",
    "    return bw_image\n",
    "\n",
    "\n",
    "def create_animated_gif(\n",
    "    model_results,\n",
    "    max_depths,\n",
    "    color_model,\n",
    "    font,\n",
    "    font_small,\n",
    "    left_pad,\n",
    "    upper_pad,\n",
    "    lower_pad,\n",
    "):\n",
    "    # List to store the concatenated images\n",
    "    concat_images = []\n",
    "\n",
    "    for max_depth in max_depths:\n",
    "        img = model_results[color_model][max_depth][\"image\"]\n",
    "\n",
    "        # create draw object\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Define text and font\n",
    "        text_depth = f\"max_depth = {max_depth:02d}\"\n",
    "        text_label = color_model.upper()\n",
    "\n",
    "        # Get bounding box for text to calculate width and height\n",
    "        bbox = draw.textbbox((0, 0), text_depth, font=font_small)\n",
    "        width, height = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "\n",
    "        # Set position for the depth text to be centered\n",
    "        position_depth = ((width) // 2, img.height - height - lower_pad)\n",
    "\n",
    "        # Set positions for color model label\n",
    "        position_label = (left_pad, upper_pad)\n",
    "\n",
    "        # Draw the texts on the image\n",
    "        draw.text(position_label, text_label, fill=\"white\", font=font)\n",
    "        draw.text(position_depth, text_depth, fill=\"white\", font=font_small)\n",
    "\n",
    "        # Add concatenated image to the list\n",
    "        concat_images.append(img)\n",
    "\n",
    "    # Create animated gif\n",
    "    concat_images[0].save(\n",
    "        f\"output_gifs/animated_{color_model}.gif\",\n",
    "        save_all=True,\n",
    "        append_images=concat_images[1:],\n",
    "        loop=0,\n",
    "        duration=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(Image.open(\"images/vangogh-original.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\"output_images\", \"output_gifs\"]\n",
    "\n",
    "for directory in directories:\n",
    "    pathlib.Path(directory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to black and white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_image = convert_to_bw_image(data)\n",
    "bw_image.save(\"output_images/vangogh-bw.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "for color_model in color_models:\n",
    "    model_results[color_model] = {}\n",
    "    X, y = process_image(data, color_model)\n",
    "    for max_depth in max_depths:\n",
    "        model_results[color_model][max_depth] = {}\n",
    "        (\n",
    "            model_results[color_model][max_depth][\"regressor\"],\n",
    "            model_results[color_model][max_depth][\"image\"],\n",
    "        ) = create_regressor_and_image(X, y, data, max_depth, color_model)\n",
    "        model_results[color_model][max_depth][\"image\"].save(\n",
    "            f\"output_images/{color_model}_{max_depth}.png\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create animated gifs for each color model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "for color_model in color_models:\n",
    "    create_animated_gif(\n",
    "        model_results,\n",
    "        max_depths,\n",
    "        color_model,\n",
    "        font,\n",
    "        font_small,\n",
    "        left_pad,\n",
    "        upper_pad,\n",
    "        lower_pad,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_gifs/animated_bw.gif\" width=\"30%\" /> <img src=\"output_gifs/animated_rgb.gif\" width=\"30%\" /> <img src=\"output_gifs/animated_hsv.gif\" width=\"30%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
